\section{Evaluations}
\subsection{Checking High-Level Security Properties}\label{SecResults} 

Using the techniques of Section~\ref{sec:highlevel}, we checked for
several realistic applications whether they respect the security
properties presented in Section~\ref{SecHighLevelSecProp}, and
actually found some violations.  This section presents these results
for the PACAP case study of Gemplus, focusing on the atomicity properties.


\subsubsection{Core-annotations for Atomicity Properties}

The core-annotations related to the atomicity properties specify the
methods related to the transaction mechanism declared in class
\texttt{JCSystem} of the Java Card API. As explained above, a static
ghost variable \texttt{TRANS} is used to keep track of whether there
is a transaction in progress.  


To check for the absence of uncaught exceptions inside transactions,
we use a special feature of JACK, namely pre- and postcondition
annotations for statement blocks (as presented
in~\cite{BRL-JACK}). Block annotations are  similar to method
specifications. The propagation algorithm is adapted, so that it not
only generates annotations for methods, but also for designated
blocks. As core-annotation, we add the following annotation for
\texttt{commitTransaction}. 
\begin{verbatim}
/*@ exsures (Exception) TRANS == 0; @*/
public static native void commitTransaction() 
                          throws TransactionException;
\end{verbatim}
This specifies that exceptions only can occur if no transaction is in
progress. Propagating these annotations to statement blocks ending
with a commit guarantees that if exceptions are thrown, they have to
be caught within the transaction.

Finally, in order to check that only a bounded number of retries of
pin-verification is possible, we annotate the method \texttt{check}
(declared in the interface \texttt{Pin} in the
standard Java Card API) with a precondition, requiring that no
transaction is in progress.
\begin{verbatim}
/*@ requires TRANS == 0; @*/
public boolean check(byte[] pin, short offset, byte length);
\end{verbatim}
Note: one could enforce a weaker property than not checking
PIN in transactions, but it is good practice to do so.

\subsubsection{Checking atomicity}
The method of Section~\ref{sec:highlevel} has been applied on
industrial examples of TPD applications to check that atomicity
properties are respected.



 We used the core-annotations as presented above, and
propagated these throughout the applications.

For both applications we found that they contained no nested
transactions, and that they did not contain attempts to verify pin
codes within transactions. All proof obligations generated
\emph{w.r.t.}~these properties are trivial and can be discharged
immediately. However, to emphasize once more the usefulness of having
a tool for generating annotations, in the PACAP case study we
encountered cases where a single transaction gave rise to twenty-three
annotations in five different classes. When writing these annotations
manually, it is very easy to forget some of them.

Finally, in the PACAP application we found transactions containing
uncaught exceptions. Consider for example the following code fragment.
\begin{verbatim}
void appExchangeCurrency(...) { 
  ...
  /*@ exsures (Exception) TRANS == 0; @*/ 
  { ...
  JCSystem.beginTransaction();      
  try {balance.setValue(decimal2); ...}
  catch (DecimalException e) {
    ISOException.throwIt(PurseApplet.DECIMAL_OVERFLOW); }
  JCSystem.commitTransaction();
  } ... }
\end{verbatim}
The method \texttt{setValue} that is called can actually throw a
decimal exception, which would lead to throwing an ISO exception, and
the transaction would not be committed. This clearly violates the
security policy as described in
Section~\ref{SecHighLevelSecProp}. After propagating the
core-annotations, and computing the appropriate proof obligations,
this violation is found automatically.




\subsection{Low-Footprint Java-to-Native Compilation}
Memory footprint and safety features of Java come at the price of a slower program execution, which can be a problem when the host device already has a limited processing power. To improve the runtime performances of Java systems, a common practice is to translate some parts of the program bytecode into native code.
Doing so removes the interpretation layer and improves the execution speed, but also greatly increases the memory footprint of the program: it is expected that native code is about three to four times the size of its Java counterpart. This is explained by the less-compact form of native instructions, but also by the fact that many safety-checks that are implemented by the virtual machine must be reproduced in the native code. For instance, before dereferencing a pointer, the virtual machine checks whether it is \texttt{null} and, if it is, throws a \texttt{NullPointerException}. Every time a bytecode that implements such safety-behaviors is compiled into native code, these behaviors must be reproduced as well, leading to an explosion of the code size. Indeed, a large part of the Java bytecode implement these safety mechanisms.

%Although the runtime checks are necessary to the safety of the Java virtual machine, they are most of the time used as a protection mechanism against programming errors or malicious code: A runtime exception should be the result of an exceptional, unexpected program behavior and is rarely thrown when executing sane code - doing so is considered poor programming practice. The safety checks are therefore without effect most of the time, and, in the case of native code, uselessly enlarge the code size.

%Several studies proposed to factorize these checks or in some case to eliminate them, but none proposed a complete elimination without hazarding the system security. 
Here, we use formal proofs to ensure that run-time checks can never be true into a program, which allows us to completely and safely eliminate them from the generated native code. The programs to optimize are JML-annotated against runtime exceptions and verified by the Java Applet Correctness Kit (JACK~\cite{BRL-JACK}). We have been able to remove almost all of the runtime checks on tested programs, and obtained native ARM thumb code which size was comparable to the original bytecode. 
More details can be found in a companion document~\cite{mariela06:cardis}.

Verifying that a bytecode program does not throw Runtime exceptions using JACK involves several stages:
\begin{enumerate}
\item writing the JML specification at the source level of the application, which expresses that no runtime exceptions are thrown.
\item compiling the Java sources and their JML specification.
\item generating the verification conditions over the bytecode and its BML specification, and proving the verification conditions. Once the verifications are proved, information about which instructions can be compiled without runtime checks is inserted in user defined attributes of the class file.
\item using these class file attributes in order to optimize the generated native code. When a bytecode that has one or more runtime checks in its semantics is being compiled, the bytecode attribute is checked in order to make sure that the checks are necessary. It indicates that the exceptional condition has been proved to never happen, then the runtime check is not generated.
\end{enumerate}

%Our approach benefits from the accurateness of the JML specification and from the bytecode verification condition generator. Performing the verification over the bytecode allows to easily establish a relationship between the proof obligations generated over the bytecode and the bytecode instructions to optimized.
%
%In the rest of this section, we explain in detail all the stages of the optimization procedure.
%
%\paragraph{Methodology for Writing Specification Against Runtime Exception}

%We now illustrate with an example which annotations must be generated in order to check if a method may throw an exception. Figure~\ref{fig:jmlexample}\footnote{although the analysis that we describe is on bytecode level, for the sake of readability, the examples are also given on source level} shows a Java method annotated with a JML specification. The method \verb!clear! declared in class \verb!Code_Table! receives an integer parameter \verb!size! and assigns \verb!0! to all the elements in the array field \verb!tab! whose indexes are smaller than the value of the parameter \verb!size!. The specification of the method guarantees that if every caller respects the method precondition and if every execution of the method guarantees its postcondition then the method \verb!clear! never throws an exception of type or subtype \verb!java.lang.Exception!\footnote{Note that every Java runtime exception is a subclass of \texttt{java.lang.Exception}}. This is expressed by the class and method specification contracts.
%First, a class invariant is declared which states that once an instance of type \verb!Code_Table! is created, its array field \verb!tab! is not null. The class invariant guarantees that no method will throw a \verb!NullPointerException! when dereferencing (directly or indirectly) \verb!tab!.

%\begin{figure}
%\begin{verbatim}
%final class Code_Table {
%  private/*@spec_public */short tab[];

%  //@invariant tab != null;

%  ...

%  //@requires size <= tab.length;
%  //@ensures true;
%  //@exsures (Exception) false;
%  public void clear(int size) {
%  1  int code;
%  2  //@loop_modifies code, tab[*];
%  3  //@loop_invariant code <= size && code >= 0;
%  4  for (code = 0; code < size; code++) {
%  5    tab[code] = 0;
%     }
%  }
%}
%\end{verbatim}

%\caption{\sc A JML-annotated method}
%\label{fig:jmlexample}
%\end{figure}

%The method precondition requires the \verb!size! parameter to be smaller than the length of \verb!tab!. The normal postcondition, introduced by the keyword \verb!ensures!, basically says that the method will always terminate normally, by declaring that the set of final states in case of normal termination includes all the possible final states, i.e. that the predicate \verb!true! holds after the method's normal execution\footnote{Actually, after terminating execution the method guarantees that the first \texttt{size} elements of the array tab will be equal to 0, but as this information is not relevant to proving that the method will not throw runtime exceptions we omit it}. On the other hand, the exceptional postcondition for the exception \texttt{java.lang.Exception} says that the method will not throw any exception of type \texttt{java.lang.Exception} (which includes all runtime exceptions). This is done by declaring that the set of final states in the exceptional termination case is empty, i.e. the predicate \texttt{false} holds if an exception caused the termination of the method. The loop invariant says that the array accesses are between index \verb!0! and index \verb!size - 1! of the array \verb!tab!, which guarantees that no loop iteration will cause a \verb!ArrayIndexOutOfBoundsException! since the precondition requires that \verb!size <= tab.length!.

%Once the source code is completed by the JML specification, the Java source is compiled using a normal non-optimizing Java compiler and verfication conditions are generated by the JACK bytecode-plugin.

%\paragraph{From Program Proofs to Program Optimizations }
%\label{proofs}
%In this phase, the bytecode instructions that can safely be executed without runtime checks are identified. Depending on the complexity of the verification conditions, Jack can discharge them to the fully automatic prover Simplify, or to the Coq and AtelierB interactive theorem prover assistants.
%There are several conditions to be met for a bytecode instruction to be optimized safely -- the precondition of the method the instruction belongs to must hold every time the method is invoked, and the verification condition related to the exceptional termination must also hold.
%Once identified, proved instructions can be marked in user-defined attributes of the class file so that the compiler can find them.

%\paragraph{More Precise Optimizations}

%\label{section:optimprecise}

In order to optimize an instruction in a method body, the method precondition must be established at every call site and the method implementation must be proved not to throw an exception under the assumption that the method precondition holds. This means that if there is one call site where the method precondition is broken then no instruction in the method body will be optimized.

Actually, the analysis may be less conservative and therefore more precise. We illustrate with an example how
one can achieve more precise results.

Consider the example of figure \ref{fig:jmlpreciseex}. On the left side of the figure, we show source code for method \verb!setTo0! which sets the \verb!buff! array element at index \verb!k! to 0. On the right side, we show the bytecode of the same method. The \texttt{iastore} instruction at index \texttt{3} may throw two different runtime exceptions: \texttt{NullPointerException}, or \texttt{ArrayIndexOutOfBoundException}. For the method execution to be safe (i.e. no Runtime exception is thrown), the method requires some certain conditions to be fulfilled by its callers. Thus, the method's precondition states that the \verb!buff! array parameter must not be null and that the \verb!k! parameter must be inside the bounds of \verb!buff!. If at all call sites we can establish that the \verb!buff! parameter is always different from null, but there are sites at which an unsafe parameter \verb!k! is passed the optimization for \texttt{NullPointerException} is still safe although the optimization for \texttt{ArrayIndexOutOfBoundException} is not possible. In order to obtain this kind of preciseness, a solution is to classify the preconditions of a method with respect to what kind of runtime exception they protect the code from. For our example, this classification consists of two groups of preconditions. The first is related to \texttt{NullPointerException}, i.e. \texttt{buff != null} and the second consists of preconditions related to \texttt{ArrayIndexOutOfBoundException}, i.e. \verb! k >= 0 && k <= buff.length!. Thus, if the preconditions of one group are established at all call sites, the optimizations concerning the respective exception can be performed even if the preconditions concerning other exceptions are not satisfied.

\begin{figure}
\begin{minipage}[b]{0.5\linewidth}
\begin{verbatim}
//@requires buff != null;
//@requires k >= 0 ;
//@requires k <= buff.length;
//@ensures true;
//@exsures (Exception) false;
public void setTo0(int k,int[] buff)
{
  buff[k] = 0;
}
\end{verbatim}
\end{minipage}
\hspace{.5cm}
\begin{minipage}[b]{0.4\linewidth}
 \begin{verbatim}
 0 aload_2
 1 iload_1
 2 iconst_0
 3 iastore
 4 return
\end{verbatim}
\end{minipage}
\caption{\sc The source code and bytecode of a method that may throw several exceptions}
\label{fig:jmlpreciseex}
\end{figure}

\subsubsection{Experimental Results}
\label{sec:experiments}

This section presents an application and evaluation of our method on various Java programs.

\paragraph{Methodology}

We have measured the efficiency of our method on two kinds of programs, that implement features commonly met in restrained and embedded devices. \benchname{crypt} and \benchname{banking} are two smartcard-range applications.
%\benchname{crypt} is a cryptography benchmark from the Java Grande benchmarks suite, and \benchname{banking} is a little banking application with full JML annotations used in~\cite{BRL-JACK}.
\benchname{scheduler} and \benchname{tcpip} are two embeddable system components written in Java, which are actually used in the JITS~\cite{JITSWebsite} platform.
%\benchname{scheduler} implements a threads scheduling mechanism, where scheduling policies are Java classes. \benchname{tcpip} is a TCP/IP stack entirely written in Java, that implements the TCP, UDP, IP, SLIP and ICMP protocols. 
These two components are written with low-footprint in mind ; however, the overall system performance would greatly benefit from having them available in native form, provided the memory footprint cost is not too important.

For every program, we look at both the number of runtime exception check sites that we are able to remove from the native code, and the impact on the memory footprint of the natively-compiled methods with respect to the unoptimized native version and the original bytecode. The memory footprint measurements were obtained by compiling the C source file generated by the JITS AOT compiler using GCC 4.0.0 with optimization option \texttt{-Os}, for the ARM platform in thumb mode. The native methods sizes are obtained by inspecting the .o file with \texttt{nm}, and getting the size for the symbol corresponding to the native method.

Regarding the number of eliminated exception check sites, we also
compare our results with the ones obtained using the JC virtual
machine version 1.4.6. The results were obtained by running the
\texttt{jcgen} program on the benchmark classes, and counting the
number of explicit exception check sites in the generated C code. 
%We
%are not comparing the memory footprints obtained with the JITS and JC
%AOT compilers, for this result would not be pertinent. Indeed, JC and
%JITS have very different ways to generate native code. JITS targets
%low memory footprint, and JC runtime performance. As a consequence, a
%runtime exception check site in JC is heavier than one in JITS, which
%would falsify the experiments. Suffices to say that our approach could
%be applied on any AOT compiler, and that the most relevant measurement
%is the number of runtime exception check sites that remains in the
%final binary - our measurements on the native code memory footprint
%are just here to evaluate the size impact of exception check sites.

\paragraph{Results}
\label{results}
Table \ref{tab:nbexcsites} shows the results obtained on the four tested programs. The three first columns indicate the number of check sites present in the bytecode, the number of explicit check sites emitted by JC, and the number of check sites that we were unable to prove useless and that must be present in our optimized AOT code. The last columns give the memory footprints of the bytecode, unoptimized native code, and native code from which all proved exception check sites are removed.

\begin{table}
\begin{center}
  \begin{tabular}{|l|r@{\extracolsep{0.2cm}}rrrrr|r@{\extracolsep{0.1cm}}rrr|}
    \hline
    \multirow{2}*{Program} & \multicolumn{3}{c}{\# of exception check sites} & \multicolumn{3}{c|}{Memory footprint (bytes)} & \multicolumn{2}{c}{Source size} & \multicolumn{2}{c|}{Proved lemmas}\\
    \cline{2-4} \cline{5-7} \cline{7-9} \cline{10-11} & Bytecode & ~~~~~~JC & AOT+ & Bytecode & AOT & AOT+ & Code & JML & Automatic & Manual\\
    \hline
    \benchname{crypt} & 190 & 79 & 1 & 1256 & 5330 & 1592 & 4113 & 1882 & 227 & 77\\
    \benchname{banking} & 170 & 12 & 0 & 2320 & 5634 & 3582 & 11845 & 15775 & 379 & 159\\
    \benchname{scheduler} & 215 & 25 & 0 & 2208 & 5416 & 2504 & 12539 & 3399 & 226 & 49\\
    \benchname{tcpip} & 1893 & 288 & 0 & 15497 & 41540 & 18064 & 83017 & 15379 & 2233 & 2191\\
    \hline
  \end{tabular}
\end{center}
\label{tab:nbexcsites}
\caption{Number of exception check sites and memory footprints when compiled for ARM thumb + Human work on the tested programs}
\end{table}

On all the tested programs, we were able to prove that all but one exception check site could be removed. The only site that we were unable to prove from \benchname{crypt} is linked to a division, which divisor is a computed value that we were unable to prove not equal to zero. JC has to retain 16\ of all the exception check sites, with a particular mention for \benchname{crypt}, which is mainly made of array accessed and had more remaining check sites.
The memory footprints obtained clearly show the heavy overhead induced
by exception check sites. Despite of the fact that the exception
throwing convention has deliberately been simplified for our
experiments, optimized native code is less than half the size of the
non-optimized native code. The native code of \benchname{crypt}, which
heavily uses arrays, is actually made of exception checking code at
70\%.
Comparing the size of the optimized native versions with the bytecode
reveals that proved native code is just slightly bigger than
bytecode. The native code of \benchname{crypt} is 27\% bigger than its
bytecode version. Native \benchname{scheduler} only weights 13.5\%
more that its bytecode, \benchname{tcpip} 16.5\%, while
\benchname{banking} is 54\% heavier. This last result is explained by
the fact that, being an application and not a system component,
\benchname{banking} includes many native-to-java method invokations
for calling system services. The native-to-java calling convention is
costly in JITS, which artificially increases the result.


Finally, table \ref{tab:nbexcsites} details the human work required to obtain the proofs on the benchmark programs, by comparing the amount of JML code with respect to the comments-free source code of the programs. It also details how many lemmas had to be manually proved.
%\begin{table}
%\caption{Human work on the tested programs}
%\begin{center}
%  \begin{tabular}{|l|r@{\extracolsep{0.5cm}}rrr|}
%    \hline
%    \multirow{2}*{Program} & \multicolumn{2}{c}{Source code size (bytes)} & \multicolumn{2}{c|}{Proved lemmas}\\
%    \cline{2-3} \cline{4-5} \cline{6-7} & ~~~~~~~~~Code & JML & Automatically & Manually\\
%    \hline
%    \benchname{crypt} & 4113 & 1882 & 227 & 77 \\
%    \benchname{banking} & 11845 & 15775 & 379 & 159\\
%    \benchname{scheduler} & 12539 & 3399 & 226 & 49\\
%    \benchname{tcpip} & 83017 & 15379 & 2233 & 2191\\
%    \hline
%  \end{tabular}
%\end{center}
%\label{tab:implication}
%\end{table}
On the three programs that are annotated for the unique purpose of our
study, the JML overhead is about 30\% of the code size. The
\benchname{banking} program was annotated in order to prove other
properties, and because of this is made of more JML annotations than
actual code. Most of the lemmas could be proved by Simplify, but a
non-neglectable part needed human-assistance with Coq. The most
demanding application was the TCP/IP stack. Because of its complexity,
nearly half of the lemmas could not be proved automatically.
The gain in terms of memory footprint obtained using our approach is
therefore real. One may also wonder whether the runtime performance of
such optimized methods would be increased. We did the measurements,
and only noticed a very slight, almost undetectable, improvement of
the execution speed of the programs. This is explained by the fact
that the exception check sites conditions are always false when
evaluated, and therefore the amount of supplementary code executed is
very low. The bodies of the proved runtime exception check sites are,
actually, dead code that is never executed.



\subsection{Memory consumption}
Another application is a framework to perform a precise analysis of resource consumption for
Java bytecode programs (for the clarity of the explanations all
examples in the introduction deal with source code).  
%In order
%to illustrate the principles of our approach, let us consider the
%following program:
%\begin{verbatim}
%public void m (A a) {
%  if (a == null) 
%    { a = new A();  }  
%  a.b = new B(); }
%\end{verbatim}
In order to model the memory consumption of program, we introduce
a {\em ghost} variable \verb!Mem! that accounts for
memory consumption; more precisely, the value of \verb!Mem! at any
given program point is meant to provide an upper bound to the amount
of memory consumed so far. To keep track of the memory consumption, we
perform immediately after every bytecode that allocates memory an
increment of \verb!Mem!\ by the amount of memory consumed by the
allocation. Thus, if the programmer specifies that \verb!ka! and
\verb!kb! is the memory consumed by the allocation of an instance of
class \verb!A! and \verb!B! respectively, a program must be
annotated like, for example:
\begin{verbatim} 
public void m (A a) {
 if (a == null) 
   {a = new A(); //set Mem = Mem + ka;}  
 a.b = new B(); //set Mem = Mem + kb; }
\end{verbatim}
Such annotations allow to compute at run-time the memory consumed by
the program. However, we are interested in static prediction of memory
consumption, and resort to pre- and postconditions to this end.  
%Even for a simple example as above, one can express the specification
%at different levels of granularity. For example, fixing the amount of
%memory that the program may use, \verb!Max!, one can specify that the
%method will use at most \verb!ka! $+$ \verb!kb! memory units and will not
%overpass the authorized limit \verb!Max!, with the following
%specification:
%$$
%\begin{array}{ll}
%//@ \ \requires & \Mem + \srcCode{ka} + \srcCode{kb} \leq \Max \\
%//@ \ \ensures &  \Mem \leq \oldp(\Mem) + \srcCode{ka} + \srcCode{kb}     
%\end{array}
%$$
%\begin{verbatim}
%    public void m (A a) { ... }
%\end{verbatim}
%Or try to be more precise and relate memory consumption to inputs with
%the following specification:
%$$
%\begin{array}{l}
%//@ \ \requires \ \srcCode{a==null} \Rightarrow \Mem + \srcCode{ka} + \srcCode{kb} \leq \Max \\ 
%\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \land \ \srcCode{!(a==null)} \Rightarrow \Mem + \srcCode{kb} \leq \Max \\
%//@ \ \ensures \\
%\ \ \ \ \ \ \   \old\srcCode{(a)==null} \Rightarrow \Mem \leq \oldp(\Mem) + \srcCode{ka} + \srcCode{kb} \\ 
%\ \ \ \ \ \ \land \ !(\old\srcCode{(a)==null}) \Rightarrow \Mem \leq \oldp(\Mem) + \srcCode{kb}    
%\end{array}
%$$
%\begin{verbatim}
%  public void m (A a) { ... }
%\end{verbatim}
%More complex specifications are also possible: one can
%take into account whether the program will throw an exception or not by
%using (possibly several) exceptional postconditions stating that
%$\texttt{k}_{\texttt{E}}$ memory units are allocated in case the
%method exits on exception \texttt{E}.
The main characteristics of our approach are:
\begin{itemize}
\item \emph{Precision:} our analysis allows to specify and enforce
precise memory consumption policies, including those that take
into account the results of branching statements or the values of
parameters in method calls. Being based on program logics, which are
very versatile, the precision of our analysis can be further improved
by using it in combination with other analysis, such as control flow
analysis and exception analysis;


\item \emph{Correctness:} our analysis exploits existing program logics
which are (usually) already known to be sound;
%In fact, it is immediate
%to derive the soundness of our analysis from the soundness of the program
%logic, provided ghost annotations that update memory consumption variables
%are consistent with an instrumented semantics that  extends the language
%operational semantics with a suitable cost model that reflects resource
%usage;

\item \emph{Language coverage:} our analysis relies on the existence
of a verification condition generator for the programming language at
hand, and is therefore scalable to complex programming features.
%In
%the course of the document, we shall illustrate applications of our
%approach to programs featuring recursive methods, method
%overriding and exceptions;


\item \emph{Usability:} our approach can be put to practice
immediately using existing verification tools for program logics. We
have applied it to annotated Java bytecode programs using the JACK
verification environment. It is also
possible to use our approach on JML annotated Java source;




\item \emph{Annotation and proof generation:} in contrast to other
techniques, our approach requires user interaction,
both for specifying the program and for proving that it meets its
specification.  In order to reduce the burden of the user, we have
developed heuristics that infer automatically part of the annotations,
and use automatic procedures to help discharge many proof obligations
automatically.
\end{itemize}
Furthermore, our analysis may be used to guarantee that no memory
allocation is performed in undesirable states of the application,
namely after initialization or during a transaction in a Java Card.
More information can be found in a companion document~\cite{gmg05:sefm}.

%\subsubsection{Modeling Memory Consumption}\label{sec:verif}
The objective of this section is to demonstrate how the user can
annotate and verify programs in order to obtain an upper bound on
memory consumption. 
We describe now the principles of our
approach, and finally show
how it can be applied to non-trivial examples involving recursive
methods and exceptions.

%\paragraph{Principles}
Let us begin with a very simple memory consumption policy which aims
at enforcing that  programs do not consume more than
some fixed amount of memory \Max . To enforce this policy, we first
introduce a ghost variable \Mem\ that represents at any given point of
the program the memory used so far. Then, we annotate the program both
with the policy and with additional statements that will be used to
check that the application respects the policy.


\begin{itemize}
\item The precondition of the method \method\ should ensure
that there must be enough free memory for the method
execution. Suppose that we know an upper bound of the allocations done
by method \method\ in any execution. We will denote this upper
bound by \allocMethod{\method}. Thus there must be at least
\allocMethod{\method}\ free memory units from the allowed \Max\ when
method \method\ starts execution. Thus the precondition for \method\ is:
$$
//@ \ \requires \ \Mem + \allocMethod{\method}  \leq \Max.
$$
The precondition of the program entry point (i.e., the \textit{main} 
method from which an application may start its execution) should 
also give the initial memory used by the virtual machine, i.e.
require that variable \Mem\ is equal to some fixed constant.

\item The normal postcondition of the method $\method$ must
guarantee that the memory allocated during a normal execution of
$\method$ is not more than some fixed number \allocMethod{\method}\
of memory units. Thus for the method $\method$ the postcondition is:
$$
//@ \ \ensures \ \Mem \leq \oldp(\Mem) + \allocMethod{\method}.
$$

\item The exceptional postcondition of the method $\method$ must
specify that the memory allocated during an execution of $\method$ 
terminating by throwing an exception \texttt{Exception} is not more
than \allocMethod{\method} units. Thus for the method $\method$ the
exceptional postcondition is:
$$
\begin{array}{l}
//@ \ \exsures{Exception} \\
\ \ \ \ \ \ \ \ \ \ \ \ \ \  \Mem \leq \oldp(\Mem) + \allocMethod{\method}.
\end{array}
$$




\item For every instruction that allocates memory the ghost
variable \Mem\ must be updated accordingly. For the purpose of
this document, we only consider dynamic object creation with the 
bytecode \new; arrays are left for future work and briefly discussed 
in the conclusion. 

In order to perform the update for \new\ bytecodes, we assume given a
function $\texttt{allocInst}: Class \rightarrow int$ gives an
estimation of the memory used by an instance of a class. Then at every
program point where a bytecode \srcCode{\new \ A} is found, the ghost
variable \Mem\ must be incremented by $\allocInstance{A}$. This is
achieved by inserting a ghost assignment associated with any \new\
instruction, as shown below:
$$
\srcCode{\new \ A} \ \ \ \ // \ghostSet \ \Mem = \Mem + \allocInstance{A}.
$$
\end{itemize}
%\paragraph{Correctness} An important question is whether our approach
%guarantees that the memory allocated by a given program conforms to
%the memory consumption policy imposed by BML annotations. We can
%prove that our approach is correct by instrumenting the operational
%semantics of the bytecode language to reflect memory
%consumption. Concretely, this is achieved by extending states with the
%special variable \Mem, and describing for each bytecode and for ghost
%assignments the effect of the weakest precondition calculus on \Mem\
%(in the fragment of the language considered, the only instruction to
%modify memory is \new, thus the only instruction whose weakest
%precondition calculus has an effect on \Mem\ is \new).

%We can then prove the correctness of the annotations w.r.t. the
%instrumented operational semantics, under the proviso that ghost
%assignments triggered by object creation are compatible with the
%instrumented operational semantics. 

\subsubsection{Inferring Memory Allocation}\label{sec:infer}
In the previous section, we have described how the memory consumption
of a program can be modeled in BML and verified using an appropriate
verification environment. While our examples illustrate the benefits
of our approach, especially regarding the precision of the analysis,
the applicability of our method is hampered by the cost of providing
the annotations manually. In order to reduce the burden of manually
annotating the program, one can rely on annotation assistants that
infer automatically some of the program annotations (indeed such
assistants already exist for loop invariants~\cite{NimmerE02:ISSTA} and class
invariants~\cite{log04:vmcai}). In this section, we describe an
implementation of an annotation assistant dedicated to the analysis of
memory consumption, and illustrate its functioning on an example.
 
The annotation assistant performs two tasks. First, it inserts the
ghost assignments on appropriate places; for this task, the user must
provide annotations about the memory required to create objects of the
given classes. 

Second, it inserts pre- and postconditions for each method. In this case, variants for loops and recursive methods may be given by the user or be
synthesized through appropriate mechanisms.  Based on this
information, the annotation assistant recursively computes the memory
allocated on each loop and method. Essentially, it finds the maximal
memory that can be allocated in a method by exploring all its possible
execution paths.

The function $\allocMethod{.}$ is defined as follows:
\begin{itemize}
\item \textbf{Input:} Annotated bytecode of a method \method, and memory
policies for methods that are called by \method;

\item \textbf{Output:} Upper bound of the memory allocated by \method;

\item \textbf{Body:} The first step is to compute the loop structure
of the method, then to compute an upper bound to the memory allocated
by each loop using its variant, and then to compute an upper bound to
the memory allocated along each execution path.
\end{itemize}

The annotation assistant currently synthesizes only simple memory
policies (i.e., whenever the memory consumption policy does not depend
on the input).  Furthermore, it does not deal with arrays,
subroutines, nor exceptions, and is restricted to loops with a unique
entry point. The latter restriction is not critical because it
accommodates code produced by non-optimizing compilers. However, a
pre-analysis could give us all the entry points of more general loops,
for instance by the algorithms given in \cite{CJPS05cmu}; our approach
may be thus applied straightforwardly. 


